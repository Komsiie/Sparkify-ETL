**Sparkify ETL Pipeline**
This project aims to facilitate data analysis for Sparkify, a startup focused on understanding user activity and song preferences on their music streaming app. The analytics team at Sparkify seeks to gain insights into the songs users are listening to. However, they currently lack a streamlined method to query their data, which is stored in JSON logs detailing user activity and metadata on songs within the app.

To address this challenge, the project implements the following solutions:
Data Modeling with MySQL: Structuring the data in MySQL tables to enable efficient querying and analysis.
ETL Pipeline: Building an Extract, Transform, Load (ETL) pipeline using Python, which transforms data from JSON files into dimension and fact tables following a "star" schema.

**Overview**
Sparkify is a music streaming service that generates a vast amount of data on user interactions with songs. It's essential to organize and structure this data efficiently to enable data analysis and insights. The ETL process extracts raw log data, transforms it into a suitable format, and loads it into MySQL tables for easier querying and analysis.

**ETL Process**
The ETL process consists of three main steps:
Extract: Raw log data is obtained from log files generated by the Sparkify application.
Transform: The extracted data is transformed to match the required formats and structures for efficient analysis. This includes cleaning the data, filtering out irrelevant information, and formatting it according to the database schema.
Load: The transformed data is loaded into MySQL database tables, where it can be easily queried and analyzed by Sparkify's data analysts and engineers.

**Project Structure**
The project structure is organized as follows:
data: Contains the raw log files generated by Sparkify.
etl.ipynb: Jupyter Notebook containing the ETL process code, allowing for interactive exploration and development.
sql_queries.py: Script to create database tables based on the defined schema. Defines SQL queries used for creating database tables and inserting data.
README.md: Documentation providing an overview of the project, instructions for setup, and usage.

**Setup and Usage**
To set up and run the Sparkify ETL project, follow these steps:
1. Ensure you have Python 3.x installed on your system.
2. Install required Python dependencies by running: 
	pip install -r requirements.txt
3. Set up a MySQL database to load the transformed data.
4. Install the MySQL Connector Python package:
	pip install mysql-connector-python
5. Modify the database connection settings in sql_queries.py if necessary.
6. Run the sql_queries.py script to create the necessary database tables:
7. Execute the ETL process using Jupyter Notebook (etl.ipynb). Modify the folder paths and database connection settings as needed.
8. Once the ETL process is complete, the transformed data should be loaded into the MySQL database tables.
9. Perform data analysis and query the loaded data using SQL queries or other analysis tools.

